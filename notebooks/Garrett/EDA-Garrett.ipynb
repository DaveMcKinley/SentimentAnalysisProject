{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model that can rate the sentiment of a Tweet based on its content.\n",
    "\n",
    "You'll build an NLP model to analyze Twitter sentiment about Apple and Google products. The dataset comes from CrowdFlower via data.world. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\n",
    "\n",
    "Aim for a Proof of Concept There are many approaches to NLP problems - start with something simple and iterate from there. For example, you could start by limiting your analysis to positive and negative Tweets only, allowing you to build a binary classifier. Then you could add in the neutral Tweets to build out a multiclass classifier. You may also consider using some of the more advanced NLP methods in the Mod 4 Appendix.\n",
    "\n",
    "Evaluation Evaluating multiclass classifiers can be trickier than binary classifiers because there are multiple ways to mis-classify an observation, and some errors are more problematic than others. Use the business problem that your NLP project sets out to solve to inform your choice of evaluation metrics.\n",
    "\n",
    "Data: https://data.world/crowdflower/brands-and-product-emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk related imports\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judge-1377884607_tweet_product_company.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/judge-1377884607_tweet_product_company.csv', encoding = 'unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tweet = df['tweet_text'][0]\n",
    "first_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase\n",
    "first_tweet_lower = first_tweet.lower()\n",
    "first_tweet_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'i',\n",
       " 'have',\n",
       " 'a',\n",
       " '3g',\n",
       " 'iphone',\n",
       " '.',\n",
       " 'after',\n",
       " '3',\n",
       " 'hrs',\n",
       " 'tweeting',\n",
       " 'at',\n",
       " '#rise_austin',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'dead',\n",
       " '!',\n",
       " 'i',\n",
       " 'need',\n",
       " 'to',\n",
       " 'upgrade',\n",
       " '.',\n",
       " 'plugin',\n",
       " 'stations',\n",
       " 'at',\n",
       " '#sxsw',\n",
       " '.']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweet tokenizer\n",
    "tweet_tknzr = TweetTokenizer(strip_handles=True)\n",
    "first_tweet_lower_tt = tweet_tknzr.tokenize(first_tweet_lower)\n",
    "first_tweet_lower_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. i have a 3g iphone . after 3 hrs tweeting at #rise_austin , it was dead ! i need to upgrade . plugin stations at #sxsw .'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn tokenized words back into tweet\n",
    "first_tweet_lower_tweet = \" \".join(first_tweet_lower_tt)\n",
    "first_tweet_lower_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have',\n",
       " '3g',\n",
       " 'iphone',\n",
       " 'after',\n",
       " 'hrs',\n",
       " 'tweeting',\n",
       " 'at',\n",
       " 'rise_austin',\n",
       " 'it',\n",
       " 'was',\n",
       " 'dead',\n",
       " 'need',\n",
       " 'to',\n",
       " 'upgrade',\n",
       " 'plugin',\n",
       " 'stations',\n",
       " 'at',\n",
       " 'sxsw']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use regexptokenizer\n",
    "pattern = r\"(?u)\\w{2,}\" # select all words with 2 or more characters\n",
    "         #r\"(?u)\\b\\w\\w+\\b\"\n",
    "         #r'\\w+'     <-REMOVES PUNCTUATION\n",
    "regexp_tknzr = RegexpTokenizer(pattern)\n",
    "first_tweet_regexp = regexp_tknzr.tokenize(first_tweet_lower_tweet)\n",
    "first_tweet_regexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3g',\n",
       " 'iphone',\n",
       " 'hrs',\n",
       " 'tweeting',\n",
       " 'rise_austin',\n",
       " 'dead',\n",
       " 'need',\n",
       " 'upgrade',\n",
       " 'plugin',\n",
       " 'stations',\n",
       " 'sxsw']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of stopwords in English\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "#remove stopwords\n",
    "first_tweet_sw_removed = [word for word in first_tweet_regexp if word not in stopwords_list]\n",
    "first_tweet_sw_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3g',\n",
       " 'iphone',\n",
       " 'hr',\n",
       " 'tweeting',\n",
       " 'rise_austin',\n",
       " 'dead',\n",
       " 'need',\n",
       " 'upgrade',\n",
       " 'plugin',\n",
       " 'station',\n",
       " 'sxsw']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create lemma object\n",
    "lemma = WordNetLemmatizer()\n",
    "first_tweet_lemma = [lemma.lemmatize(token) for token in first_tweet_sw_removed]\n",
    "first_tweet_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering/Prepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "          Sentiment  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns = {'tweet_text': 'Tweet', \n",
    "                         'emotion_in_tweet_is_directed_at': 'Product', \n",
    "                         'is_there_an_emotion_directed_at_a_brand_or_product': 'Sentiment'})\n",
    "df.head() #Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x8cÏ¡\\x8eÏà\\x8aü_\\x8b\\x81Ê\\x8b\\x81Î\\x8b\\x81Ò\\x8b\\x81£\\x8b\\x81Á\\x8bââ\\x8b\\x81_\\x8b\\x81£\\x8b\\x81\\x8f\\x8bâ_\\x8bÛâRT @mention Google Tests \\x89ÛÏCheck-in Offers\\x89Û\\x9d At #SXSW {link}'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'].iloc[9092]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'].iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([6, 9092], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['Tweet'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet           0\n",
       "Product      5787\n",
       "Sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5374\n",
       "Positive emotion                      2970\n",
       "Negative emotion                       569\n",
       "I can't tell                           156\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   iPhone\n",
       "1       iPad or iPhone App\n",
       "2                     iPad\n",
       "3       iPad or iPhone App\n",
       "4                   Google\n",
       "               ...        \n",
       "9087             Undefined\n",
       "9088                  iPad\n",
       "9089             Undefined\n",
       "9090             Undefined\n",
       "9091             Undefined\n",
       "Name: Product, Length: 9069, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Product.fillna(\"Undefined\", inplace = True)\n",
    "df[\"Product\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Undefined                          5787\n",
       "iPad                                945\n",
       "Apple                               659\n",
       "iPad or iPhone App                  469\n",
       "Google                              428\n",
       "iPhone                              296\n",
       "Other Google product or service     293\n",
       "Android App                          80\n",
       "Android                              77\n",
       "Other Apple product or service       35\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9069 entries, 0 to 9091\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Tweet      9069 non-null   object\n",
      " 1   Product    9069 non-null   object\n",
      " 2   Sentiment  9069 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 283.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple           5361\n",
       "Google          2756\n",
       "Undetermined     739\n",
       "Both             213\n",
       "Name: Brand, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_brand(Product, Tweet): #Building function to determine Brand\n",
    "    brand = 'Undetermined' #Labeling brand as Undetermined\n",
    "    if ((Product.lower().__contains__('google')) or (Product.lower().__contains__('android'))): #Labeling Google\n",
    "        brand = 'Google' #Unless tweet contains google or android\n",
    "    elif ((Product.lower().__contains__('apple')) or (Product.lower().__contains__('ip'))): #Labeling Apple\n",
    "        brand = 'Apple' #Unless tweet contains apple or ip\n",
    "    \n",
    "    if (brand == 'Undetermined'): \n",
    "        lower_tweet = Tweet.lower() #Making tweet lowercase\n",
    "        is_google = (lower_tweet.__contains__('google')) or (lower_tweet.__contains__('android')) #Undetermined google\n",
    "        is_apple = (lower_tweet.__contains__('apple')) or (lower_tweet.__contains__('ip')) #Undetermined apple\n",
    "        \n",
    "        if (is_google and is_apple): #if it has both identifiers in the tweet\n",
    "            brand = 'Both' #Labeling brand as both\n",
    "        elif (is_google):\n",
    "            brand = 'Google' #Labeling brand as Google\n",
    "        elif (is_apple):\n",
    "            brand = 'Apple' #Labeling brand as Apple\n",
    "    \n",
    "    return brand\n",
    "\n",
    "df['Brand'] = df.apply(lambda x: find_brand(x['Product'], x['Tweet']), axis = 1) #Applying function to column\n",
    "df['Brand'].value_counts() #Reviewing value counts of each class within brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == \"Positive emotion\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "   Sentiment   Brand  \n",
       "0          0   Apple  \n",
       "1          1   Apple  \n",
       "2          1   Apple  \n",
       "3          0   Apple  \n",
       "4          1  Google  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday: Create an Apple and Google DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_df = df[df['Brand']=='Apple']\n",
    "google_df = df[df['Brand']==\"Google\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "5  @teachntech00 New iPad Apps For #SpeechTherapy...           Undefined   \n",
       "\n",
       "   Sentiment  Brand  \n",
       "0          0  Apple  \n",
       "1          1  Apple  \n",
       "2          1  Apple  \n",
       "3          0  Apple  \n",
       "5          0  Apple  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
       "      <td>Android</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW Wi...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Foursquare ups the game, just in time for #SXS...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweet      Product  Sentiment  \\\n",
       "4   @sxtxstate great stuff on Fri #SXSW: Marissa M...       Google          1   \n",
       "7   #SXSW is just starting, #CTIA is around the co...      Android          1   \n",
       "10  Excited to meet the @samsungmobileus at #sxsw ...      Android          1   \n",
       "11  Find &amp; Start Impromptu Parties at #SXSW Wi...  Android App          1   \n",
       "12  Foursquare ups the game, just in time for #SXS...  Android App          1   \n",
       "\n",
       "     Brand  \n",
       "4   Google  \n",
       "7   Google  \n",
       "10  Google  \n",
       "11  Google  \n",
       "12  Google  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = google_df[['Tweet']]\n",
    "y = google_df['Sentiment']\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday: Doing 2 Train_Test_Splits on whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[['Tweet']]\n",
    "# y = df['Sentiment']\n",
    "# X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.710753\n",
       "1    0.289247\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BASELINE UNDERSTANDING\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #If we did a multi class\n",
    "# dict_sent = {'No emotion toward brand or product':1, \n",
    "#              'Positive emotion':2,\n",
    "#              'Negative emotion':0,\n",
    "#              \"I can't tell\": 1}\n",
    "# df['Sentiment'] = df['Sentiment'].map(dict_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Preprocess targets\n",
    "# y_train = y_train.apply(lambda x: 1 if x == \"Positive emotion\" else 0)\n",
    "# y_val = y_val.apply(lambda x: 1 if x == \"Positive emotion\" else 0)\n",
    "# y_test = y_test.apply(lambda x: 1 if x == \"Positive emotion\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>RT @mention google to launch a social network ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>Google party! #sxsw (@mention GSD&amp;amp;M w/ 157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>Google 80's Party! #SXSW (@mention Maggie Mae'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>RT @mention &amp;quot;Google maps: Route around tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>RT @mention #sxsw news: Google to Launch Major...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet\n",
       "5866  RT @mention google to launch a social network ...\n",
       "7797  Google party! #sxsw (@mention GSD&amp;M w/ 157...\n",
       "1515  Google 80's Party! #SXSW (@mention Maggie Mae'...\n",
       "5181  RT @mention &quot;Google maps: Route around tr...\n",
       "5308  RT @mention #sxsw news: Google to Launch Major..."
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1860, 1)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 1)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate necessary tools\n",
    "tokenizer = RegexpTokenizer(r\"(?u)\\w{3,}\")\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "lemma = WordNetLemmatizer()\n",
    "tweet_tknzr = TweetTokenizer(strip_handles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(text):\n",
    "    no_handle = tweet_tknzr.tokenize(text)\n",
    "    tweet = \" \".join(no_handle) \n",
    "    #remove http websites, pound sign, any words in brackets, any words with ampersand right in front\n",
    "        # ?, www dot com websites, links, videos, and non english characters\n",
    "    #clean = re.sub(\"((^|\\W)@\\b([-a-zA-Z0-9._]{3,25})\\b) \\\n",
    "        #|(&[a-z]+;)|([^\\w\\s]) \\\n",
    "    clean = re.sub(\"(https?:\\/\\/\\S+) \\\n",
    "                   |(#[A-Za-z0-9_]+) \\\n",
    "                   |(\\{([a-zA-Z].+)\\}) \\\n",
    "                   |(&[a-z]+;) \\\n",
    "                   |(www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com))\\\n",
    "                   |({link})\\\n",
    "                   |(\\[video\\])\\\n",
    "                   |([^\\x00-\\x7F]+\\ *(?:[^\\x00-\\x7F]| )*)\",\" \", tweet)\n",
    "    lower = clean.lower()\n",
    "    token_list = tokenizer.tokenize(lower)\n",
    "    stopwords_removed=[token for token in token_list if token not in stopwords_list]\n",
    "    lemma_list = [lemma.lemmatize(token) for token in stopwords_removed]\n",
    "    cleaned_string = \" \".join(lemma_list) #Turn the lemma list into a string for the Vectorizer\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google launch social network sxsw today'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "clean_tweets(X_train['Tweet'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-171-221299341c06>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Tweet'] = X_train['Tweet'].apply(lambda x: clean_tweets(x))\n",
      "<ipython-input-171-221299341c06>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val['Tweet'] = X_val['Tweet'].apply(lambda x: clean_tweets(x))\n",
      "<ipython-input-171-221299341c06>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Tweet'] = X_test['Tweet'].apply(lambda x: clean_tweets(x))\n"
     ]
    }
   ],
   "source": [
    "X_train['Tweet'] = X_train['Tweet'].apply(lambda x: clean_tweets(x))\n",
    "X_val['Tweet'] = X_val['Tweet'].apply(lambda x: clean_tweets(x))\n",
    "X_test['Tweet'] = X_test['Tweet'].apply(lambda x: clean_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>google launch social network sxsw today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>google party sxsw gsd 157 others link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>google party sxsw maggie mae others link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>google map route around traffic saving user ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>sxsw news google launch major new social netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>thing got smarmcake sxsw writeup google ontolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>location pixieengine google say future locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>failure google buzz google latitude google cir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>google offering reward title check in starting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>killer thought paying service probably sold re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1860 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet\n",
       "5866            google launch social network sxsw today\n",
       "7797              google party sxsw gsd 157 others link\n",
       "1515           google party sxsw maggie mae others link\n",
       "5181  google map route around traffic saving user ye...\n",
       "5308  sxsw news google launch major new social netwo...\n",
       "...                                                 ...\n",
       "8467  thing got smarmcake sxsw writeup google ontolo...\n",
       "741   location pixieengine google say future locatio...\n",
       "4239  failure google buzz google latitude google cir...\n",
       "3147  google offering reward title check in starting...\n",
       "7202  killer thought paying service probably sold re...\n",
       "\n",
       "[1860 rows x 1 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>loving video google geo geek skiing lake tahoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7355</th>\n",
       "      <td>google party sxsw huge antigov lobbying initia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>sxsw social hackathon session google bing webt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>would copyright look like created today ceo pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6925</th>\n",
       "      <td>google talking topicality reputation search ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>marissa mayer google connect digital physical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>sxsw look blue hair got free android phone inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>suck google preview major new social service c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8173</th>\n",
       "      <td>hmmm google launch major new social network ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>sxsw google map mobile device link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet\n",
       "2752  loving video google geo geek skiing lake tahoe...\n",
       "7355  google party sxsw huge antigov lobbying initia...\n",
       "5505  sxsw social hackathon session google bing webt...\n",
       "2429  would copyright look like created today ceo pr...\n",
       "6925  google talking topicality reputation search ra...\n",
       "...                                                 ...\n",
       "2234  marissa mayer google connect digital physical ...\n",
       "5305  sxsw look blue hair got free android phone inf...\n",
       "5387  suck google preview major new social service c...\n",
       "8173  hmmm google launch major new social network ca...\n",
       "5255                 sxsw google map mobile device link\n",
       "\n",
       "[620 rows x 1 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5866    0\n",
       "7797    1\n",
       "1515    0\n",
       "5181    1\n",
       "5308    0\n",
       "       ..\n",
       "8467    0\n",
       "741     0\n",
       "4239    0\n",
       "3147    0\n",
       "7202    0\n",
       "Name: Sentiment, Length: 1860, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2752    0\n",
       "7355    1\n",
       "5505    0\n",
       "2429    0\n",
       "6925    1\n",
       "       ..\n",
       "2234    0\n",
       "5305    1\n",
       "5387    0\n",
       "8173    0\n",
       "5255    0\n",
       "Name: Sentiment, Length: 620, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DON'T NEED BECAUSE I ADDED A LINE TO THE CLEAN_TWEETS FUNCTION\n",
    "\n",
    "# X_train[\"Tweet\"] = X_train[\"Tweet\"].str.join(\" \")\n",
    "# X_val[\"Tweet\"] = X_val[\"Tweet\"].str.join(\" \")\n",
    "# X_test[\"Tweet\"] = X_test[\"Tweet\"].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1860x3229 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19564 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vectorizer = CountVectorizer()\n",
    "c_vectorizer.fit(X_train['Tweet'])\n",
    "X_train_c_vec = c_vectorizer.transform(X_train['Tweet'])\n",
    "X_train_c_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>10x</th>\n",
       "      <th>1100</th>\n",
       "      <th>11bil</th>\n",
       "      <th>11pm</th>\n",
       "      <th>120</th>\n",
       "      <th>1223</th>\n",
       "      <th>125</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>zation</th>\n",
       "      <th>zeiger</th>\n",
       "      <th>zeitgeist</th>\n",
       "      <th>zero</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1860 rows × 3229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  100  101  10x  1100  11bil  11pm  120  1223  125  ...  yup  zation  \\\n",
       "5866    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "7797    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "1515    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "5181    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "5308    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "...   ...  ...  ...  ...   ...    ...   ...  ...   ...  ...  ...  ...     ...   \n",
       "8467    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "741     0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "4239    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "3147    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "7202    0    0    0    0     0      0     0    0     0    0  ...    0       0   \n",
       "\n",
       "      zeiger  zeitgeist  zero  zing  zip  zombie  zoom  zuckerberg  \n",
       "5866       0          0     0     0    0       0     0           0  \n",
       "7797       0          0     0     0    0       0     0           0  \n",
       "1515       0          0     0     0    0       0     0           0  \n",
       "5181       0          0     0     0    0       0     0           0  \n",
       "5308       0          0     0     0    0       0     0           0  \n",
       "...      ...        ...   ...   ...  ...     ...   ...         ...  \n",
       "8467       0          0     0     0    0       0     0           0  \n",
       "741        0          0     0     0    0       0     0           0  \n",
       "4239       0          0     0     0    0       0     0           0  \n",
       "3147       0          0     0     0    0       0     0           0  \n",
       "7202       0          0     0     0    0       0     0           0  \n",
       "\n",
       "[1860 rows x 3229 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_c_vec_df = pd.DataFrame(X_train_c_vec.toarray(), columns=c_vectorizer.get_feature_names(), \n",
    "                              index=X_train.index)\n",
    "X_train_c_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5866    1\n",
       "7797    1\n",
       "1515    1\n",
       "5181    1\n",
       "5308    1\n",
       "       ..\n",
       "8467    1\n",
       "741     1\n",
       "4239    1\n",
       "3147    1\n",
       "7202    1\n",
       "Name: sxsw, Length: 1860, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "X_train_c_vec_df['sxsw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_c_vec = c_vectorizer.transform(X_val['Tweet'])\n",
    "X_val_c_vec_df = pd.DataFrame(X_val_c_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1860, 3229)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "    #max_df=.95,  # removes words that appear in more than 95% of docs\n",
    "    #min_df=2     # removes words that appear 2 or fewer times\n",
    "    #max_features=10\n",
    "tfidf_vectorizer.fit(X_train['Tweet'])\n",
    "X_train_tfidf_vec = tfidf_vectorizer.transform(X_train['Tweet'])\n",
    "X_val_tfidf_vec = tfidf_vectorizer.transform(X_val['Tweet'])\n",
    "X_train_tfidf_vec_df = pd.DataFrame(X_train_tfidf_vec.toarray())\n",
    "X_val_tfidf_vec_df = pd.DataFrame(X_val_tfidf_vec.toarray())\n",
    "X_train_tfidf_vec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Logistic Regression Model w/ Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9252688172043011\n",
      "0.7338709677419355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_c_vec_df, y_train)\n",
    "print(lr.score(X_train_c_vec_df, y_train))\n",
    "print(lr.score(X_val_c_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Logistic Regression Model w/ Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8139784946236559\n",
      "0.7225806451612903\n"
     ]
    }
   ],
   "source": [
    "lr_2 = LogisticRegression()\n",
    "lr_2.fit(X_train_tfidf_vec_df, y_train)\n",
    "print(lr_2.score(X_train_tfidf_vec_df, y_train))\n",
    "print(lr_2.score(X_val_tfidf_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes w/ Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8731182795698925\n",
      "0.7225806451612903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_c_vec_df, y_train)\n",
    "print(naive_bayes.score(X_train_c_vec_df, y_train))\n",
    "print(naive_bayes.score(X_val_c_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes w/ Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8370967741935483\n",
      "0.7258064516129032\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_2 = MultinomialNB()\n",
    "naive_bayes_2.fit(X_train_tfidf_vec_df, y_train)\n",
    "print(naive_bayes_2.score(X_train_tfidf_vec_df, y_train))\n",
    "print(naive_bayes_2.score(X_val_tfidf_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes w/ Tuned Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vectorizer_2 = CountVectorizer(max_df=.99,min_df=2, max_features=1000)\n",
    "    #max_df=.95,  # removes words that appear in more than 95% of docs\n",
    "    #min_df=2     # removes words that appear 2 or fewer times\n",
    "c_vectorizer_2.fit(X_train['Tweet'])\n",
    "X_train_c_vec_2 = c_vectorizer_2.transform(X_train['Tweet'])\n",
    "X_val_c_vec_2 = c_vectorizer_2.transform(X_val['Tweet'])\n",
    "X_train_c_vec_df_2 = pd.DataFrame(X_train_c_vec_2.toarray())\n",
    "X_val_c_vec_df_2 = pd.DataFrame(X_val_c_vec_2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes with tuned count vectorizer\n",
      "0.8096774193548387\n",
      "0.6887096774193548\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_3 = MultinomialNB()\n",
    "naive_bayes_3.fit(X_train_c_vec_df_2, y_train)\n",
    "print(\"naive bayes with tuned count vectorizer\")\n",
    "print(naive_bayes_3.score(X_train_c_vec_df_2, y_train))\n",
    "print(naive_bayes_3.score(X_val_c_vec_df_2, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHOLE DATASET\n",
    "# naive bayes with tuned count vectorizer\n",
    "# 0.7582094429014867\n",
    "# 0.705046545810877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_2 = TfidfVectorizer(max_df=.99,min_df=0.005, max_features=1000)\n",
    "tfidf_vectorizer_2.fit(X_train['Tweet'])\n",
    "X_train_tfidf_vec_2 = tfidf_vectorizer_2.transform(X_train['Tweet'])\n",
    "X_val_tfidf_vec_2 = tfidf_vectorizer_2.transform(X_val['Tweet'])\n",
    "X_train_tfidf_vec_df_2 = pd.DataFrame(X_train_tfidf_vec_2.toarray())\n",
    "X_val_tfidf_vec_df_2 = pd.DataFrame(X_val_tfidf_vec_2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes with tuned tfidf\n",
      "0.7709677419354839\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_4 = MultinomialNB()\n",
    "naive_bayes_4.fit(X_train_tfidf_vec_df_2, y_train)\n",
    "print(\"naive bayes with tuned tfidf\")\n",
    "print(naive_bayes_4.score(X_train_tfidf_vec_df_2, y_train))\n",
    "print(naive_bayes_4.score(X_val_tfidf_vec_df_2, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHOLE DATASET\n",
    "# naive bayes with tuned tfidf\n",
    "# 0.7162228394053259\n",
    "# 0.7011268985791279"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with max iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default count vectorizer\n",
      "0.8921744812939062\n",
      "0.739343459088682\n"
     ]
    }
   ],
   "source": [
    "lr_3 = LogisticRegression(max_iter=1000)\n",
    "lr_3.fit(X_train_c_vec_df, y_train)\n",
    "print(\"default count vectorizer\")\n",
    "print(lr_3.score(X_train_c_vec_df, y_train))\n",
    "print(lr_3.score(X_val_c_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default tfidf vectorizer\n",
      "0.800359418395687\n",
      "0.7315041646251838\n"
     ]
    }
   ],
   "source": [
    "#lr_3 = LogisticRegression(max_iter=1000)\n",
    "lr_3.fit(X_train_tfidf_vec_df, y_train)\n",
    "print(\"default tfidf vectorizer\")\n",
    "print(lr_3.score(X_train_tfidf_vec_df, y_train))\n",
    "print(lr_3.score(X_val_tfidf_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf vectorizer with tuned parameters\n",
      "0.7645809508250286\n",
      "0.7251347378735914\n"
     ]
    }
   ],
   "source": [
    "#lr_3 = LogisticRegression(max_iter=1000)\n",
    "lr_3.fit(X_train_tfidf_vec_df_2, y_train)\n",
    "print(\"tfidf vectorizer with tuned parameters\")\n",
    "print(lr_3.score(X_train_tfidf_vec_df_2, y_train))\n",
    "print(lr_3.score(X_val_tfidf_vec_df_2, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA w/ Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_c_vec_df) #Use default count vectorizer\n",
    "X_val_scaled = scaler.transform(X_val_c_vec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2916"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to import, instantiate and fit a PCA object\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = .95, random_state=42)\n",
    "pca.fit(X_train_scaled)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA with n_components=0.95, default count vectorizer, and logistic regression\n",
      "0.9516418885802973\n",
      "0.6888780009799118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# Construct a pipelines\n",
    "pipe_lr = Pipeline([('pca', pca), \n",
    "                    ('lr', LogisticRegression(random_state=42, max_iter=1000))])\n",
    "pipe_lr.fit(X_train_scaled, y_train)\n",
    "print(\"PCA with n_components=0.95, default count vectorizer, and logistic regression\")\n",
    "print(pipe_lr.score(X_train_scaled, y_train))\n",
    "print(pipe_lr.score(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_mnb = Pipeline([('pca', pca), \n",
    "#                     ('mnb', MultinomialNB())])\n",
    "# pipe_mnb.fit(X_train_scaled, y_train)\n",
    "# print(\"PCA with n_components=0.95, default count vectorizer, and naive bayes\")\n",
    "# print(pipe_lr.score(X_train_scaled, y_train))\n",
    "# print(pipe_lr.score(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I got an error about MultinomialNB not having negative values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA w/ Tuned TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2 = StandardScaler()\n",
    "X_train_scaled_2 = scaler_2.fit_transform(X_train_tfidf_vec_df_2) #Use tuned tfidf vectorizer\n",
    "X_val_scaled_2 = scaler_2.transform(X_val_tfidf_vec_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1238"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_2 = PCA(n_components = .90, random_state=42)\n",
    "pca_2.fit(X_train_scaled_2)\n",
    "pca_2.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA with n_components=0.95, tuned tfidf vectorizer, and naive bayes\n",
      "0.8307466100310407\n",
      "0.7074963253307203\n"
     ]
    }
   ],
   "source": [
    "pipe_lr_2 = Pipeline([('pca2', pca_2), \n",
    "                    ('lr2', LogisticRegression(random_state=42, max_iter=1000))])\n",
    "pipe_lr_2.fit(X_train_scaled_2, y_train)\n",
    "print(\"PCA with n_components=0.95, tuned tfidf vectorizer, and naive bayes\")\n",
    "print(pipe_lr_2.score(X_train_scaled_2, y_train))\n",
    "print(pipe_lr_2.score(X_val_scaled_2, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline and Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix, plot_roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.16672111, 0.13967609, 0.13760495, 0.13788915, 0.14039111]),\n",
       " 'score_time': array([0.02055192, 0.01950383, 0.01929021, 0.01866698, 0.01906395]),\n",
       " 'test_accuracy': array([0.74040816, 0.71486928, 0.75408497, 0.71078431, 0.74264706]),\n",
       " 'train_accuracy': array([0.90093954, 0.90034715, 0.89810088, 0.90320604, 0.90055136]),\n",
       " 'test_precision': array([0.64259928, 0.58545455, 0.68060837, 0.57      , 0.6539924 ]),\n",
       " 'train_precision': array([0.93301812, 0.93019608, 0.92093023, 0.93843725, 0.93502377]),\n",
       " 'test_roc_auc': array([0.75917814, 0.72217647, 0.7512428 , 0.72191419, 0.7299032 ]),\n",
       " 'train_roc_auc': array([0.96578595, 0.96697679, 0.96357515, 0.96520491, 0.96583773])}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_logreg = Pipeline(steps=[\n",
    "    ('count_vectorizer', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression(random_state=42))\n",
    "])\n",
    "cv = cross_validate(pipe_logreg, X_train['Tweet'], y_train, return_train_score=True, \\\n",
    "                    scoring=['accuracy', 'precision','roc_auc'])\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.35563898, 1.32724214, 1.3579073 , 1.32797313, 1.31642294]),\n",
       " 'score_time': array([0.09072995, 0.08811212, 0.09062457, 0.0879178 , 0.08778   ]),\n",
       " 'test_accuracy': array([0.71510204, 0.71568627, 0.71650327, 0.72058824, 0.70915033]),\n",
       " 'train_accuracy': array([0.95118464, 0.94853992, 0.94894834, 0.94813151, 0.94935675]),\n",
       " 'test_precision': array([0.59677419, 0.59022556, 0.59760956, 0.608     , 0.57936508]),\n",
       " 'train_precision': array([0.96030116, 0.95997239, 0.96450939, 0.95676047, 0.96650384]),\n",
       " 'test_roc_auc': array([0.71998169, 0.71112087, 0.70720185, 0.71120474, 0.70237856]),\n",
       " 'train_roc_auc': array([0.99131925, 0.99003833, 0.99008938, 0.98925492, 0.98986803])}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfc = Pipeline(steps=[\n",
    "    ('tfidf_vectorizer', TfidfVectorizer(max_df=.99,min_df=0.005, max_features=1000)),\n",
    "    ('rfc', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "cv = cross_validate(pipe_rfc, X_train['Tweet'], y_train, return_train_score=True, \\\n",
    "                    scoring=['accuracy', 'precision','roc_auc'])\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf_vectorizer',\n",
       "                                        TfidfVectorizer(max_df=0.99,\n",
       "                                                        max_features=1000,\n",
       "                                                        min_df=0.005)),\n",
       "                                       ('rfc',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'rfc__class_weight': ['balanced'],\n",
       "                         'rfc__max_depth': [25, 50, 100],\n",
       "                         'rfc__min_samples_leaf': [1, 3, 5],\n",
       "                         'rfc__n_estimators': [500, 1000, 1500],\n",
       "                         'rfc__random_state': [42]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_rfc = {\n",
    "    \"rfc__max_depth\" :[25, 50, 100],\n",
    "    \"rfc__min_samples_leaf\" : [1, 3, 5],\n",
    "    \"rfc__n_estimators\": [500, 1000, 1500],\n",
    "    \"rfc__class_weight\" :['balanced'],\n",
    "    \"rfc__random_state\":[42]\n",
    "}\n",
    "grid_rfc = GridSearchCV(estimator = pipe_rfc, param_grid=pg_rfc, scoring='accuracy',\n",
    "                        return_train_score = True)\n",
    "grid_rfc.fit(X_train['Tweet'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_rfc__class_weight</th>\n",
       "      <th>param_rfc__max_depth</th>\n",
       "      <th>param_rfc__min_samples_leaf</th>\n",
       "      <th>param_rfc__n_estimators</th>\n",
       "      <th>param_rfc__random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.318658</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>0.104045</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.703673</td>\n",
       "      <td>0.692810</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.693627</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.692369</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.573491</td>\n",
       "      <td>0.096270</td>\n",
       "      <td>0.190555</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.702041</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.693513</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.840107</td>\n",
       "      <td>0.197343</td>\n",
       "      <td>0.282089</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.701224</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>0.702614</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.693513</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.624615</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.093181</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.686531</td>\n",
       "      <td>0.678105</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.682190</td>\n",
       "      <td>0.658497</td>\n",
       "      <td>0.677339</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.238793</td>\n",
       "      <td>0.054916</td>\n",
       "      <td>0.177897</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.662582</td>\n",
       "      <td>0.679789</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.739683</td>\n",
       "      <td>0.064339</td>\n",
       "      <td>0.270101</td>\n",
       "      <td>0.023248</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.693061</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.679789</td>\n",
       "      <td>0.011646</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.456939</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.089320</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.679184</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.678105</td>\n",
       "      <td>0.678105</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.672928</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.861272</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.169892</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.683265</td>\n",
       "      <td>0.665033</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>0.673745</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.256708</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>0.247809</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.684898</td>\n",
       "      <td>0.660948</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.659314</td>\n",
       "      <td>0.673744</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.277533</td>\n",
       "      <td>0.067883</td>\n",
       "      <td>0.135058</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.706939</td>\n",
       "      <td>0.705065</td>\n",
       "      <td>0.710784</td>\n",
       "      <td>0.709967</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.706257</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.576495</td>\n",
       "      <td>0.056847</td>\n",
       "      <td>0.261771</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.704248</td>\n",
       "      <td>0.711601</td>\n",
       "      <td>0.709967</td>\n",
       "      <td>0.702614</td>\n",
       "      <td>0.707401</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.737133</td>\n",
       "      <td>0.172062</td>\n",
       "      <td>0.389302</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.706939</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.707516</td>\n",
       "      <td>0.706699</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.703643</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.290345</td>\n",
       "      <td>0.013868</td>\n",
       "      <td>0.115204</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.695510</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.685458</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.686488</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.540483</td>\n",
       "      <td>0.033923</td>\n",
       "      <td>0.221917</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.694694</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.669935</td>\n",
       "      <td>0.685834</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.789670</td>\n",
       "      <td>0.057322</td>\n",
       "      <td>0.340070</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.684641</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.685344</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.989135</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.109460</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.689796</td>\n",
       "      <td>0.674020</td>\n",
       "      <td>0.675654</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.657680</td>\n",
       "      <td>0.674397</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.948893</td>\n",
       "      <td>0.032455</td>\n",
       "      <td>0.209460</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.689796</td>\n",
       "      <td>0.671569</td>\n",
       "      <td>0.678105</td>\n",
       "      <td>0.677288</td>\n",
       "      <td>0.662582</td>\n",
       "      <td>0.675868</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.881535</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>0.309699</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.675654</td>\n",
       "      <td>0.662582</td>\n",
       "      <td>0.675214</td>\n",
       "      <td>0.009694</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.203749</td>\n",
       "      <td>0.024041</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.706699</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.701520</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.346109</td>\n",
       "      <td>0.076506</td>\n",
       "      <td>0.324994</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.701797</td>\n",
       "      <td>0.700980</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.701797</td>\n",
       "      <td>0.701683</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18.480057</td>\n",
       "      <td>0.111807</td>\n",
       "      <td>0.483685</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.698776</td>\n",
       "      <td>0.702614</td>\n",
       "      <td>0.697712</td>\n",
       "      <td>0.706699</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.701847</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.815874</td>\n",
       "      <td>0.033027</td>\n",
       "      <td>0.132577</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.688980</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.677288</td>\n",
       "      <td>0.686162</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.583226</td>\n",
       "      <td>0.061434</td>\n",
       "      <td>0.255994</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.688980</td>\n",
       "      <td>0.682190</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.678922</td>\n",
       "      <td>0.685672</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.360275</td>\n",
       "      <td>0.109339</td>\n",
       "      <td>0.379568</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.686325</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.271639</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.688163</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>0.674020</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.673254</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.529314</td>\n",
       "      <td>0.076020</td>\n",
       "      <td>0.231062</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.672386</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.676520</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.768269</td>\n",
       "      <td>0.110884</td>\n",
       "      <td>0.346861</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.694694</td>\n",
       "      <td>0.669118</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.318658      0.058411         0.104045        0.008570   \n",
       "1        4.573491      0.096270         0.190555        0.002927   \n",
       "2        6.840107      0.197343         0.282089        0.002942   \n",
       "3        1.624615      0.020397         0.093181        0.001943   \n",
       "4        3.238793      0.054916         0.177897        0.002050   \n",
       "5        4.739683      0.064339         0.270101        0.023248   \n",
       "6        1.456939      0.015529         0.089320        0.000478   \n",
       "7        2.861272      0.034160         0.169892        0.002214   \n",
       "8        4.256708      0.030177         0.247809        0.001791   \n",
       "9        4.277533      0.067883         0.135058        0.000474   \n",
       "10       8.576495      0.056847         0.261771        0.001782   \n",
       "11      12.737133      0.172062         0.389302        0.001426   \n",
       "12       2.290345      0.013868         0.115204        0.000478   \n",
       "13       4.540483      0.033923         0.221917        0.001201   \n",
       "14       6.789670      0.057322         0.340070        0.021676   \n",
       "15       1.989135      0.011709         0.109460        0.001683   \n",
       "16       3.948893      0.032455         0.209460        0.001994   \n",
       "17       5.881535      0.042614         0.309699        0.002136   \n",
       "18       6.203749      0.024041         0.166000        0.001573   \n",
       "19      12.346109      0.076506         0.324994        0.002842   \n",
       "20      18.480057      0.111807         0.483685        0.005899   \n",
       "21       2.815874      0.033027         0.132577        0.001857   \n",
       "22       5.583226      0.061434         0.255994        0.003229   \n",
       "23       8.360275      0.109339         0.379568        0.005834   \n",
       "24       2.271639      0.031224         0.119724        0.001922   \n",
       "25       4.529314      0.076020         0.231062        0.003380   \n",
       "26       6.768269      0.110884         0.346861        0.008413   \n",
       "\n",
       "   param_rfc__class_weight param_rfc__max_depth param_rfc__min_samples_leaf  \\\n",
       "0                 balanced                   25                           1   \n",
       "1                 balanced                   25                           1   \n",
       "2                 balanced                   25                           1   \n",
       "3                 balanced                   25                           3   \n",
       "4                 balanced                   25                           3   \n",
       "5                 balanced                   25                           3   \n",
       "6                 balanced                   25                           5   \n",
       "7                 balanced                   25                           5   \n",
       "8                 balanced                   25                           5   \n",
       "9                 balanced                   50                           1   \n",
       "10                balanced                   50                           1   \n",
       "11                balanced                   50                           1   \n",
       "12                balanced                   50                           3   \n",
       "13                balanced                   50                           3   \n",
       "14                balanced                   50                           3   \n",
       "15                balanced                   50                           5   \n",
       "16                balanced                   50                           5   \n",
       "17                balanced                   50                           5   \n",
       "18                balanced                  100                           1   \n",
       "19                balanced                  100                           1   \n",
       "20                balanced                  100                           1   \n",
       "21                balanced                  100                           3   \n",
       "22                balanced                  100                           3   \n",
       "23                balanced                  100                           3   \n",
       "24                balanced                  100                           5   \n",
       "25                balanced                  100                           5   \n",
       "26                balanced                  100                           5   \n",
       "\n",
       "   param_rfc__n_estimators param_rfc__random_state  \\\n",
       "0                      500                      42   \n",
       "1                     1000                      42   \n",
       "2                     1500                      42   \n",
       "3                      500                      42   \n",
       "4                     1000                      42   \n",
       "5                     1500                      42   \n",
       "6                      500                      42   \n",
       "7                     1000                      42   \n",
       "8                     1500                      42   \n",
       "9                      500                      42   \n",
       "10                    1000                      42   \n",
       "11                    1500                      42   \n",
       "12                     500                      42   \n",
       "13                    1000                      42   \n",
       "14                    1500                      42   \n",
       "15                     500                      42   \n",
       "16                    1000                      42   \n",
       "17                    1500                      42   \n",
       "18                     500                      42   \n",
       "19                    1000                      42   \n",
       "20                    1500                      42   \n",
       "21                     500                      42   \n",
       "22                    1000                      42   \n",
       "23                    1500                      42   \n",
       "24                     500                      42   \n",
       "25                    1000                      42   \n",
       "26                    1500                      42   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.703673   \n",
       "1   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.702041   \n",
       "2   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.701224   \n",
       "3   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.686531   \n",
       "4   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.692245   \n",
       "5   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.693061   \n",
       "6   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.679184   \n",
       "7   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.683265   \n",
       "8   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.684898   \n",
       "9   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.706939   \n",
       "10  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.708571   \n",
       "11  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.706939   \n",
       "12  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.695510   \n",
       "13  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.694694   \n",
       "14  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.693878   \n",
       "15  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.689796   \n",
       "16  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.689796   \n",
       "17  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.692245   \n",
       "18  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.697959   \n",
       "19  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.697959   \n",
       "20  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.698776   \n",
       "21  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.688980   \n",
       "22  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.688980   \n",
       "23  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.692245   \n",
       "24  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.688163   \n",
       "25  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.697143   \n",
       "26  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.694694   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.692810           0.695261           0.693627   \n",
       "1            0.691176           0.698529           0.695261   \n",
       "2            0.687092           0.702614           0.695261   \n",
       "3            0.678105           0.681373           0.682190   \n",
       "4            0.673203           0.687092           0.683824   \n",
       "5            0.670752           0.687092           0.686275   \n",
       "6            0.667484           0.678105           0.678105   \n",
       "7            0.665033           0.687092           0.673203   \n",
       "8            0.660948           0.688725           0.674837   \n",
       "9            0.705065           0.710784           0.709967   \n",
       "10           0.704248           0.711601           0.709967   \n",
       "11           0.698529           0.707516           0.706699   \n",
       "12           0.690359           0.685458           0.686275   \n",
       "13           0.688725           0.687908           0.687908   \n",
       "14           0.688725           0.684641           0.688725   \n",
       "15           0.674020           0.675654           0.674837   \n",
       "16           0.671569           0.678105           0.677288   \n",
       "17           0.670752           0.674837           0.675654   \n",
       "18           0.696078           0.703431           0.706699   \n",
       "19           0.701797           0.700980           0.705882   \n",
       "20           0.702614           0.697712           0.706699   \n",
       "21           0.687908           0.690359           0.686275   \n",
       "22           0.682190           0.690359           0.687908   \n",
       "23           0.683824           0.688725           0.690359   \n",
       "24           0.660131           0.674020           0.676471   \n",
       "25           0.670752           0.674837           0.672386   \n",
       "26           0.669118           0.674837           0.676471   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.676471         0.692369        0.008840                9  \n",
       "1            0.680556         0.693513        0.007407                8  \n",
       "2            0.681373         0.693513        0.008173                7  \n",
       "3            0.658497         0.677339        0.009797               18  \n",
       "4            0.662582         0.679789        0.010623               16  \n",
       "5            0.661765         0.679789        0.011646               17  \n",
       "6            0.661765         0.672928        0.007028               27  \n",
       "7            0.660131         0.673745        0.010299               24  \n",
       "8            0.659314         0.673744        0.012017               25  \n",
       "9            0.698529         0.706257        0.004379                2  \n",
       "10           0.702614         0.707401        0.003419                1  \n",
       "11           0.698529         0.703643        0.004183                3  \n",
       "12           0.674837         0.686488        0.006830               10  \n",
       "13           0.669935         0.685834        0.008346               13  \n",
       "14           0.670752         0.685344        0.007863               15  \n",
       "15           0.657680         0.674397        0.010183               23  \n",
       "16           0.662582         0.675868        0.008900               21  \n",
       "17           0.662582         0.675214        0.009694               22  \n",
       "18           0.703431         0.701520        0.003910                6  \n",
       "19           0.701797         0.701683        0.002531                5  \n",
       "20           0.703431         0.701847        0.003261                4  \n",
       "21           0.677288         0.686162        0.004634               12  \n",
       "22           0.678922         0.685672        0.004373               14  \n",
       "23           0.676471         0.686325        0.005665               11  \n",
       "24           0.667484         0.673254        0.009367               26  \n",
       "25           0.667484         0.676520        0.010585               19  \n",
       "26           0.666667         0.676357        0.009848               20  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_rfc.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__class_weight': 'balanced',\n",
       " 'rfc__max_depth': 50,\n",
       " 'rfc__min_samples_leaf': 1,\n",
       " 'rfc__n_estimators': 1000,\n",
       " 'rfc__random_state': 42}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
