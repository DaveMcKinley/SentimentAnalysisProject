{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model that can rate the sentiment of a Tweet based on its content.\n",
    "\n",
    "You'll build an NLP model to analyze Twitter sentiment about Apple and Google products. The dataset comes from CrowdFlower via data.world. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\n",
    "\n",
    "Aim for a Proof of Concept There are many approaches to NLP problems - start with something simple and iterate from there. For example, you could start by limiting your analysis to positive and negative Tweets only, allowing you to build a binary classifier. Then you could add in the neutral Tweets to build out a multiclass classifier. You may also consider using some of the more advanced NLP methods in the Mod 4 Appendix.\n",
    "\n",
    "Evaluation Evaluating multiclass classifiers can be trickier than binary classifiers because there are multiple ways to mis-classify an observation, and some errors are more problematic than others. Use the business problem that your NLP project sets out to solve to inform your choice of evaluation metrics.\n",
    "\n",
    "Data: https://data.world/crowdflower/brands-and-product-emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk related imports\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judge-1377884607_tweet_product_company.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/judge-1377884607_tweet_product_company.csv', encoding = 'unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tweet = df['tweet_text'][0]\n",
    "first_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase\n",
    "first_tweet_lower = first_tweet.lower()\n",
    "first_tweet_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'i',\n",
       " 'have',\n",
       " 'a',\n",
       " '3g',\n",
       " 'iphone',\n",
       " '.',\n",
       " 'after',\n",
       " '3',\n",
       " 'hrs',\n",
       " 'tweeting',\n",
       " 'at',\n",
       " '#rise_austin',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'dead',\n",
       " '!',\n",
       " 'i',\n",
       " 'need',\n",
       " 'to',\n",
       " 'upgrade',\n",
       " '.',\n",
       " 'plugin',\n",
       " 'stations',\n",
       " 'at',\n",
       " '#sxsw',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweet tokenizer\n",
    "tweet_tknzr = TweetTokenizer(strip_handles=True)\n",
    "first_tweet_lower_tt = tweet_tknzr.tokenize(first_tweet_lower)\n",
    "first_tweet_lower_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. i have a 3g iphone . after 3 hrs tweeting at #rise_austin , it was dead ! i need to upgrade . plugin stations at #sxsw .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn tokenized words back into tweet\n",
    "first_tweet_lower_tweet = \" \".join(first_tweet_lower_tt)\n",
    "first_tweet_lower_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have',\n",
       " '3g',\n",
       " 'iphone',\n",
       " 'after',\n",
       " 'hrs',\n",
       " 'tweeting',\n",
       " 'at',\n",
       " 'rise_austin',\n",
       " 'it',\n",
       " 'was',\n",
       " 'dead',\n",
       " 'need',\n",
       " 'to',\n",
       " 'upgrade',\n",
       " 'plugin',\n",
       " 'stations',\n",
       " 'at',\n",
       " 'sxsw']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use regexptokenizer\n",
    "pattern = r\"(?u)\\w{2,}\" # select all words with 2 or more characters\n",
    "         #r\"(?u)\\b\\w\\w+\\b\"\n",
    "         #r'\\w+'     <-REMOVES PUNCTUATION\n",
    "regexp_tknzr = RegexpTokenizer(pattern)\n",
    "first_tweet_regexp = regexp_tknzr.tokenize(first_tweet_lower_tweet)\n",
    "first_tweet_regexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3g',\n",
       " 'iphone',\n",
       " 'hrs',\n",
       " 'tweeting',\n",
       " 'rise_austin',\n",
       " 'dead',\n",
       " 'need',\n",
       " 'upgrade',\n",
       " 'plugin',\n",
       " 'stations',\n",
       " 'sxsw']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of stopwords in English\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "#remove stopwords\n",
    "first_tweet_sw_removed = [word for word in first_tweet_regexp if word not in stopwords_list]\n",
    "first_tweet_sw_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3g',\n",
       " 'iphone',\n",
       " 'hr',\n",
       " 'tweeting',\n",
       " 'rise_austin',\n",
       " 'dead',\n",
       " 'need',\n",
       " 'upgrade',\n",
       " 'plugin',\n",
       " 'station',\n",
       " 'sxsw']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create lemma object\n",
    "lemma = WordNetLemmatizer()\n",
    "first_tweet_lemma = [lemma.lemmatize(token) for token in first_tweet_sw_removed]\n",
    "first_tweet_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Doing 2 Train_Test_Splits first to avoid Data Leakage.<br> Then Preprocessing each split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "          Sentiment  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns = {'tweet_text': 'Tweet', \n",
    "                         'emotion_in_tweet_is_directed_at': 'Product', \n",
    "                         'is_there_an_emotion_directed_at_a_brand_or_product': 'Sentiment'})\n",
    "df.head() #Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x8cÏ¡\\x8eÏà\\x8aü_\\x8b\\x81Ê\\x8b\\x81Î\\x8b\\x81Ò\\x8b\\x81£\\x8b\\x81Á\\x8bââ\\x8b\\x81_\\x8b\\x81£\\x8b\\x81\\x8f\\x8bâ_\\x8bÛâRT @mention Google Tests \\x89ÛÏCheck-in Offers\\x89Û\\x9d At #SXSW {link}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'].iloc[9092]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'].iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([6, 9092], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['Tweet'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet           0\n",
       "Product      5787\n",
       "Sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5374\n",
       "Positive emotion                      2970\n",
       "Negative emotion                       569\n",
       "I can't tell                           156\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == \"Positive emotion\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Tweet']]\n",
    "y = df['Sentiment']\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.67636\n",
       "1    0.32364\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BASELINE UNDERSTANDING\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #If we did a multi class\n",
    "# dict_sent = {'No emotion toward brand or product':1, \n",
    "#              'Positive emotion':2,\n",
    "#              'Negative emotion':0,\n",
    "#              \"I can't tell\": 1}\n",
    "# df['Sentiment'] = df['Sentiment'].map(dict_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Preprocess targets\n",
    "# y_train = y_train.apply(lambda x: 1 if x == \"Positive emotion\" else 0)\n",
    "# y_val = y_val.apply(lambda x: 1 if x == \"Positive emotion\" else 0)\n",
    "# y_test = y_test.apply(lambda x: 1 if x == \"Positive emotion\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>@mention Can we make you an iPhone case with T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>RT @mention Come party down with @mention &amp;amp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>#winning #winning - just gave away 5 red mophi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>RT @mention google &amp;amp; facebook have an offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>Rumor of Google launching their new social net...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet\n",
       "2324  @mention Can we make you an iPhone case with T...\n",
       "5632  RT @mention Come party down with @mention &amp...\n",
       "1751  #winning #winning - just gave away 5 red mophi...\n",
       "5799  RT @mention google &amp; facebook have an offi...\n",
       "3339  Rumor of Google launching their new social net..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6121, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2041, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate necessary tools\n",
    "tokenizer = RegexpTokenizer(r\"(?u)\\w{3,}\")\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "lemma = WordNetLemmatizer()\n",
    "tweet_tknzr = TweetTokenizer(strip_handles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(text):\n",
    "    no_handle = tweet_tknzr.tokenize(text)\n",
    "    tweet = \" \".join(no_handle) \n",
    "    #remove http websites, pound sign, any words in brackets, any words with ampersand right in front\n",
    "        # ?, www dot com websites, links, videos, and non english characters\n",
    "    #clean = re.sub(\"((^|\\W)@\\b([-a-zA-Z0-9._]{3,25})\\b) \\\n",
    "        #|(&[a-z]+;)|([^\\w\\s]) \\\n",
    "    clean = re.sub(\"(https?:\\/\\/\\S+) \\\n",
    "                   |(#[A-Za-z0-9_]+) \\\n",
    "                   |(\\{([a-zA-Z].+)\\}) \\\n",
    "                   |(&[a-z]+;) \\\n",
    "                   |(www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com))\\\n",
    "                   |({link})\\\n",
    "                   |(\\[video\\])\\\n",
    "                   |([^\\x00-\\x7F]+\\ *(?:[^\\x00-\\x7F]| )*)\",\" \", tweet)\n",
    "    lower = clean.lower()\n",
    "    token_list = tokenizer.tokenize(lower)\n",
    "    stopwords_removed=[token for token in token_list if token not in stopwords_list]\n",
    "    lemma_list = [lemma.lemmatize(token) for token in stopwords_removed]\n",
    "    cleaned_string = \" \".join(lemma_list) #Turn the lemma list into a string for the Vectorizer\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make iphone case ttye time sxsw want show support'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "clean_tweets(X_train['Tweet'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-221299341c06>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Tweet'] = X_train['Tweet'].apply(lambda x: clean_tweets(x))\n",
      "<ipython-input-31-221299341c06>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val['Tweet'] = X_val['Tweet'].apply(lambda x: clean_tweets(x))\n",
      "<ipython-input-31-221299341c06>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Tweet'] = X_test['Tweet'].apply(lambda x: clean_tweets(x))\n"
     ]
    }
   ],
   "source": [
    "X_train['Tweet'] = X_train['Tweet'].apply(lambda x: clean_tweets(x))\n",
    "X_val['Tweet'] = X_val['Tweet'].apply(lambda x: clean_tweets(x))\n",
    "X_test['Tweet'] = X_test['Tweet'].apply(lambda x: clean_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>make iphone case ttye time sxsw want show support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>come party google tonight sxsw link band food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>winning winning gave away red mophie juice pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>google facebook official death policy vast maj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>rumor google launching new social network call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>even security guard austin enjoy ipad time sxs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8604</th>\n",
       "      <td>attending sxsw want explore austin check austi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>apple popup store sxsw link gonnagetanipad2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>putting pop apple store sxsw smart talk unders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>thought path iphone photo app sxsw iphoneograp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6121 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet\n",
       "2324  make iphone case ttye time sxsw want show support\n",
       "5632  come party google tonight sxsw link band food ...\n",
       "1751  winning winning gave away red mophie juice pac...\n",
       "5799  google facebook official death policy vast maj...\n",
       "3339  rumor google launching new social network call...\n",
       "...                                                 ...\n",
       "5702  even security guard austin enjoy ipad time sxs...\n",
       "8604  attending sxsw want explore austin check austi...\n",
       "7836        apple popup store sxsw link gonnagetanipad2\n",
       "7504  putting pop apple store sxsw smart talk unders...\n",
       "3536  thought path iphone photo app sxsw iphoneograp...\n",
       "\n",
       "[6121 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>hootsuite mobile sxsw update iphone blackberry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>morning hearing google circle today link sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>great location choice nice timing ipad launch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>win ipad sxsw via sxsw link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>launching product sxsw plenty else join h4cker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>racing around sxsw best fueling great local fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>omg still line new ipad dieing hunger sxsw els...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7735</th>\n",
       "      <td>hour sxsw popup apple store lone security guar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>great app interface example moma target flipbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>global android activation mapped animated link...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2041 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet\n",
       "891   hootsuite mobile sxsw update iphone blackberry...\n",
       "4198      morning hearing google circle today link sxsw\n",
       "2164  great location choice nice timing ipad launch ...\n",
       "1885                        win ipad sxsw via sxsw link\n",
       "4700  launching product sxsw plenty else join h4cker...\n",
       "...                                                 ...\n",
       "1033  racing around sxsw best fueling great local fa...\n",
       "4186  omg still line new ipad dieing hunger sxsw els...\n",
       "7735  hour sxsw popup apple store lone security guar...\n",
       "8211  great app interface example moma target flipbo...\n",
       "4517  global android activation mapped animated link...\n",
       "\n",
       "[2041 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2324    0\n",
       "5632    1\n",
       "1751    0\n",
       "5799    0\n",
       "3339    0\n",
       "       ..\n",
       "5702    1\n",
       "8604    0\n",
       "7836    0\n",
       "7504    1\n",
       "3536    0\n",
       "Name: Sentiment, Length: 6121, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891     0\n",
       "4198    0\n",
       "2164    1\n",
       "1885    1\n",
       "4700    0\n",
       "       ..\n",
       "1033    0\n",
       "4186    1\n",
       "7735    0\n",
       "8211    1\n",
       "4517    0\n",
       "Name: Sentiment, Length: 2041, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DON'T NEED BECAUSE I ADDED A LINE TO THE CLEAN_TWEETS FUNCTION\n",
    "\n",
    "# X_train[\"Tweet\"] = X_train[\"Tweet\"].str.join(\" \")\n",
    "# X_val[\"Tweet\"] = X_val[\"Tweet\"].str.join(\" \")\n",
    "# X_test[\"Tweet\"] = X_test[\"Tweet\"].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6121x7145 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 63041 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vectorizer = CountVectorizer()\n",
    "c_vectorizer.fit(X_train['Tweet'])\n",
    "X_train_c_vec = c_vectorizer.transform(X_train['Tweet'])\n",
    "X_train_c_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0310apple</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>101</th>\n",
       "      <th>106</th>\n",
       "      <th>10am</th>\n",
       "      <th>10pm</th>\n",
       "      <th>10x</th>\n",
       "      <th>10x2</th>\n",
       "      <th>...</th>\n",
       "      <th>zlf</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6121 rows × 7145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  0310apple  100  1000  101  106  10am  10pm  10x  10x2  ...  zlf  \\\n",
       "2324    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "5632    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "1751    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "5799    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "3339    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "...   ...        ...  ...   ...  ...  ...   ...   ...  ...   ...  ...  ...   \n",
       "5702    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "8604    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "7836    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "7504    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "3536    0          0    0     0    0    0     0     0    0     0  ...    0   \n",
       "\n",
       "      zms  zomb  zombie  zomg  zone  zoom  zuckerberg  zynga  zzzs  \n",
       "2324    0     0       0     0     0     0           0      0     0  \n",
       "5632    0     0       0     0     0     0           0      0     0  \n",
       "1751    0     0       0     0     0     0           0      0     0  \n",
       "5799    0     0       0     0     0     0           0      0     0  \n",
       "3339    0     0       0     0     0     0           0      0     0  \n",
       "...   ...   ...     ...   ...   ...   ...         ...    ...   ...  \n",
       "5702    0     0       0     0     0     0           0      0     0  \n",
       "8604    0     0       0     0     0     0           0      0     0  \n",
       "7836    0     0       0     0     0     0           0      0     0  \n",
       "7504    0     0       0     0     0     0           0      0     0  \n",
       "3536    0     0       0     0     0     0           0      0     0  \n",
       "\n",
       "[6121 rows x 7145 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_c_vec_df = pd.DataFrame(X_train_c_vec.toarray(), columns=c_vectorizer.get_feature_names(), \n",
    "                              index=X_train.index)\n",
    "X_train_c_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2324    1\n",
       "5632    1\n",
       "1751    1\n",
       "5799    1\n",
       "3339    1\n",
       "       ..\n",
       "5702    1\n",
       "8604    1\n",
       "7836    1\n",
       "7504    1\n",
       "3536    1\n",
       "Name: sxsw, Length: 6121, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "X_train_c_vec_df['sxsw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_c_vec = c_vectorizer.transform(X_val['Tweet'])\n",
    "X_val_c_vec_df = pd.DataFrame(X_val_c_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6121, 7145)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "    #max_df=.95,  # removes words that appear in more than 95% of docs\n",
    "    #min_df=2     # removes words that appear 2 or fewer times\n",
    "    #max_features=10\n",
    "tfidf_vectorizer.fit(X_train['Tweet'])\n",
    "X_train_tfidf_vec = tfidf_vectorizer.transform(X_train['Tweet'])\n",
    "X_val_tfidf_vec = tfidf_vectorizer.transform(X_val['Tweet'])\n",
    "X_train_tfidf_vec_df = pd.DataFrame(X_train_tfidf_vec.toarray())\n",
    "X_val_tfidf_vec_df = pd.DataFrame(X_val_tfidf_vec.toarray())\n",
    "X_train_tfidf_vec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Logistic Regression Model w/ Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8921744812939062\n",
      "0.7398334149926507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_c_vec_df, y_train)\n",
    "print(lr.score(X_train_c_vec_df, y_train))\n",
    "print(lr.score(X_val_c_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Logistic Regression Model w/ Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800359418395687\n",
      "0.7315041646251838\n"
     ]
    }
   ],
   "source": [
    "lr_2 = LogisticRegression()\n",
    "lr_2.fit(X_train_tfidf_vec_df, y_train)\n",
    "print(lr_2.score(X_train_tfidf_vec_df, y_train))\n",
    "print(lr_2.score(X_val_tfidf_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes w/ Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8577029897075641\n",
      "0.7158255756981872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_c_vec_df, y_train)\n",
    "print(naive_bayes.score(X_train_c_vec_df, y_train))\n",
    "print(naive_bayes.score(X_val_c_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes w/ Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7892501225289985\n",
      "0.7123958843704067\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_2 = MultinomialNB()\n",
    "naive_bayes_2.fit(X_train_tfidf_vec_df, y_train)\n",
    "print(naive_bayes_2.score(X_train_tfidf_vec_df, y_train))\n",
    "print(naive_bayes_2.score(X_val_tfidf_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes w/ Tuned Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vectorizer_2 = CountVectorizer(max_df=.99,min_df=2, max_features=1000)\n",
    "    #max_df=.95,  # removes words that appear in more than 95% of docs\n",
    "    #min_df=2     # removes words that appear 2 or fewer times\n",
    "c_vectorizer_2.fit(X_train['Tweet'])\n",
    "X_train_c_vec_2 = c_vectorizer_2.transform(X_train['Tweet'])\n",
    "X_val_c_vec_2 = c_vectorizer_2.transform(X_val['Tweet'])\n",
    "X_train_c_vec_df_2 = pd.DataFrame(X_train_c_vec_2.toarray())\n",
    "X_val_c_vec_df_2 = pd.DataFrame(X_val_c_vec_2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes with tuned count vectorizer\n",
      "0.7582094429014867\n",
      "0.705046545810877\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_3 = MultinomialNB()\n",
    "naive_bayes_3.fit(X_train_c_vec_df_2, y_train)\n",
    "print(\"naive bayes with tuned count vectorizer\")\n",
    "print(naive_bayes_3.score(X_train_c_vec_df_2, y_train))\n",
    "print(naive_bayes_3.score(X_val_c_vec_df_2, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_2 = TfidfVectorizer(max_df=.99,min_df=0.005, max_features=1000)\n",
    "tfidf_vectorizer_2.fit(X_train['Tweet'])\n",
    "X_train_tfidf_vec_2 = tfidf_vectorizer_2.transform(X_train['Tweet'])\n",
    "X_val_tfidf_vec_2 = tfidf_vectorizer_2.transform(X_val['Tweet'])\n",
    "X_train_tfidf_vec_df_2 = pd.DataFrame(X_train_tfidf_vec_2.toarray())\n",
    "X_val_tfidf_vec_df_2 = pd.DataFrame(X_val_tfidf_vec_2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes with tuned tfidf\n",
      "0.7162228394053259\n",
      "0.7011268985791279\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_4 = MultinomialNB()\n",
    "naive_bayes_4.fit(X_train_tfidf_vec_df_2, y_train)\n",
    "print(\"naive bayes with tuned tfidf\")\n",
    "print(naive_bayes_4.score(X_train_tfidf_vec_df_2, y_train))\n",
    "print(naive_bayes_4.score(X_val_tfidf_vec_df_2, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with max iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default count vectorizer\n",
      "0.8921744812939062\n",
      "0.739343459088682\n"
     ]
    }
   ],
   "source": [
    "lr_3 = LogisticRegression(max_iter=1000)\n",
    "lr_3.fit(X_train_c_vec_df, y_train)\n",
    "print(\"default count vectorizer\")\n",
    "print(lr_3.score(X_train_c_vec_df, y_train))\n",
    "print(lr_3.score(X_val_c_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default tfidf vectorizer\n",
      "0.800359418395687\n",
      "0.7315041646251838\n"
     ]
    }
   ],
   "source": [
    "#lr_3 = LogisticRegression(max_iter=1000)\n",
    "lr_3.fit(X_train_tfidf_vec_df, y_train)\n",
    "print(\"default tfidf vectorizer\")\n",
    "print(lr_3.score(X_train_tfidf_vec_df, y_train))\n",
    "print(lr_3.score(X_val_tfidf_vec_df, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf vectorizer with tuned parameters\n",
      "0.7645809508250286\n",
      "0.7251347378735914\n"
     ]
    }
   ],
   "source": [
    "#lr_3 = LogisticRegression(max_iter=1000)\n",
    "lr_3.fit(X_train_tfidf_vec_df_2, y_train)\n",
    "print(\"tfidf vectorizer with tuned parameters\")\n",
    "print(lr_3.score(X_train_tfidf_vec_df_2, y_train))\n",
    "print(lr_3.score(X_val_tfidf_vec_df_2, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA w/ Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_c_vec_df) #Use default count vectorizer\n",
    "X_val_scaled = scaler.transform(X_val_c_vec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2916"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to import, instantiate and fit a PCA object\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = .95, random_state=42)\n",
    "pca.fit(X_train_scaled)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA with n_components=0.95, default count vectorizer, and logistic regression\n",
      "0.9516418885802973\n",
      "0.6888780009799118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# Construct a pipelines\n",
    "pipe_lr = Pipeline([('pca', pca), \n",
    "                    ('lr', LogisticRegression(random_state=42, max_iter=1000))])\n",
    "pipe_lr.fit(X_train_scaled, y_train)\n",
    "print(\"PCA with n_components=0.95, default count vectorizer, and logistic regression\")\n",
    "print(pipe_lr.score(X_train_scaled, y_train))\n",
    "print(pipe_lr.score(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_mnb = Pipeline([('pca', pca), \n",
    "#                     ('mnb', MultinomialNB())])\n",
    "# pipe_mnb.fit(X_train_scaled, y_train)\n",
    "# print(\"PCA with n_components=0.95, default count vectorizer, and naive bayes\")\n",
    "# print(pipe_lr.score(X_train_scaled, y_train))\n",
    "# print(pipe_lr.score(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I got an error about MultinomialNB not having negative values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA w/ Tuned TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2 = StandardScaler()\n",
    "X_train_scaled_2 = scaler_2.fit_transform(X_train_tfidf_vec_df_2) #Use tuned tfidf vectorizer\n",
    "X_val_scaled_2 = scaler_2.transform(X_val_tfidf_vec_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1238"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_2 = PCA(n_components = .90, random_state=42)\n",
    "pca_2.fit(X_train_scaled_2)\n",
    "pca_2.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA with n_components=0.95, tuned tfidf vectorizer, and naive bayes\n",
      "0.8307466100310407\n",
      "0.7074963253307203\n"
     ]
    }
   ],
   "source": [
    "pipe_lr_2 = Pipeline([('pca2', pca_2), \n",
    "                    ('lr2', LogisticRegression(random_state=42, max_iter=1000))])\n",
    "pipe_lr_2.fit(X_train_scaled_2, y_train)\n",
    "print(\"PCA with n_components=0.95, tuned tfidf vectorizer, and naive bayes\")\n",
    "print(pipe_lr_2.score(X_train_scaled_2, y_train))\n",
    "print(pipe_lr_2.score(X_val_scaled_2, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline and Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix, plot_roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/garrettwilliams/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.16672111, 0.13967609, 0.13760495, 0.13788915, 0.14039111]),\n",
       " 'score_time': array([0.02055192, 0.01950383, 0.01929021, 0.01866698, 0.01906395]),\n",
       " 'test_accuracy': array([0.74040816, 0.71486928, 0.75408497, 0.71078431, 0.74264706]),\n",
       " 'train_accuracy': array([0.90093954, 0.90034715, 0.89810088, 0.90320604, 0.90055136]),\n",
       " 'test_precision': array([0.64259928, 0.58545455, 0.68060837, 0.57      , 0.6539924 ]),\n",
       " 'train_precision': array([0.93301812, 0.93019608, 0.92093023, 0.93843725, 0.93502377]),\n",
       " 'test_roc_auc': array([0.75917814, 0.72217647, 0.7512428 , 0.72191419, 0.7299032 ]),\n",
       " 'train_roc_auc': array([0.96578595, 0.96697679, 0.96357515, 0.96520491, 0.96583773])}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_logreg = Pipeline(steps=[\n",
    "    ('count_vectorizer', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression(random_state=42))\n",
    "])\n",
    "cv = cross_validate(pipe_logreg, X_train['Tweet'], y_train, return_train_score=True, \\\n",
    "                    scoring=['accuracy', 'precision','roc_auc'])\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.35563898, 1.32724214, 1.3579073 , 1.32797313, 1.31642294]),\n",
       " 'score_time': array([0.09072995, 0.08811212, 0.09062457, 0.0879178 , 0.08778   ]),\n",
       " 'test_accuracy': array([0.71510204, 0.71568627, 0.71650327, 0.72058824, 0.70915033]),\n",
       " 'train_accuracy': array([0.95118464, 0.94853992, 0.94894834, 0.94813151, 0.94935675]),\n",
       " 'test_precision': array([0.59677419, 0.59022556, 0.59760956, 0.608     , 0.57936508]),\n",
       " 'train_precision': array([0.96030116, 0.95997239, 0.96450939, 0.95676047, 0.96650384]),\n",
       " 'test_roc_auc': array([0.71998169, 0.71112087, 0.70720185, 0.71120474, 0.70237856]),\n",
       " 'train_roc_auc': array([0.99131925, 0.99003833, 0.99008938, 0.98925492, 0.98986803])}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfc = Pipeline(steps=[\n",
    "    ('tfidf_vectorizer', TfidfVectorizer(max_df=.99,min_df=0.005, max_features=1000)),\n",
    "    ('rfc', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "cv = cross_validate(pipe_rfc, X_train['Tweet'], y_train, return_train_score=True, \\\n",
    "                    scoring=['accuracy', 'precision','roc_auc'])\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf_vectorizer',\n",
       "                                        TfidfVectorizer(max_df=0.99,\n",
       "                                                        max_features=1000,\n",
       "                                                        min_df=0.005)),\n",
       "                                       ('rfc',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'rfc__class_weight': ['balanced'],\n",
       "                         'rfc__max_depth': [25, 50, 100],\n",
       "                         'rfc__min_samples_leaf': [1, 3, 5],\n",
       "                         'rfc__n_estimators': [500, 1000, 1500],\n",
       "                         'rfc__random_state': [42]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_rfc = {\n",
    "    \"rfc__max_depth\" :[25, 50, 100],\n",
    "    \"rfc__min_samples_leaf\" : [1, 3, 5],\n",
    "    \"rfc__n_estimators\": [500, 1000, 1500],\n",
    "    \"rfc__class_weight\" :['balanced'],\n",
    "    \"rfc__random_state\":[42]\n",
    "}\n",
    "grid_rfc = GridSearchCV(estimator = pipe_rfc, param_grid=pg_rfc, scoring='accuracy',\n",
    "                        return_train_score = True)\n",
    "grid_rfc.fit(X_train['Tweet'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_rfc__class_weight</th>\n",
       "      <th>param_rfc__max_depth</th>\n",
       "      <th>param_rfc__min_samples_leaf</th>\n",
       "      <th>param_rfc__n_estimators</th>\n",
       "      <th>param_rfc__random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.318658</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>0.104045</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.703673</td>\n",
       "      <td>0.692810</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.693627</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.692369</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.573491</td>\n",
       "      <td>0.096270</td>\n",
       "      <td>0.190555</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.702041</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.693513</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.840107</td>\n",
       "      <td>0.197343</td>\n",
       "      <td>0.282089</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.701224</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>0.702614</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.693513</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.624615</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.093181</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.686531</td>\n",
       "      <td>0.678105</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.682190</td>\n",
       "      <td>0.658497</td>\n",
       "      <td>0.677339</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.238793</td>\n",
       "      <td>0.054916</td>\n",
       "      <td>0.177897</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.662582</td>\n",
       "      <td>0.679789</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.739683</td>\n",
       "      <td>0.064339</td>\n",
       "      <td>0.270101</td>\n",
       "      <td>0.023248</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.693061</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.679789</td>\n",
       "      <td>0.011646</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.456939</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.089320</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.679184</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.678105</td>\n",
       "      <td>0.678105</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.672928</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.861272</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.169892</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.683265</td>\n",
       "      <td>0.665033</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>0.673745</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.256708</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>0.247809</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.684898</td>\n",
       "      <td>0.660948</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.659314</td>\n",
       "      <td>0.673744</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.277533</td>\n",
       "      <td>0.067883</td>\n",
       "      <td>0.135058</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.706939</td>\n",
       "      <td>0.705065</td>\n",
       "      <td>0.710784</td>\n",
       "      <td>0.709967</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.706257</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.576495</td>\n",
       "      <td>0.056847</td>\n",
       "      <td>0.261771</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.704248</td>\n",
       "      <td>0.711601</td>\n",
       "      <td>0.709967</td>\n",
       "      <td>0.702614</td>\n",
       "      <td>0.707401</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.737133</td>\n",
       "      <td>0.172062</td>\n",
       "      <td>0.389302</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.706939</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.707516</td>\n",
       "      <td>0.706699</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.703643</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.290345</td>\n",
       "      <td>0.013868</td>\n",
       "      <td>0.115204</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.695510</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.685458</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.686488</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.540483</td>\n",
       "      <td>0.033923</td>\n",
       "      <td>0.221917</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.694694</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.669935</td>\n",
       "      <td>0.685834</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.789670</td>\n",
       "      <td>0.057322</td>\n",
       "      <td>0.340070</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.684641</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.685344</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.989135</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.109460</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.689796</td>\n",
       "      <td>0.674020</td>\n",
       "      <td>0.675654</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.657680</td>\n",
       "      <td>0.674397</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.948893</td>\n",
       "      <td>0.032455</td>\n",
       "      <td>0.209460</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.689796</td>\n",
       "      <td>0.671569</td>\n",
       "      <td>0.678105</td>\n",
       "      <td>0.677288</td>\n",
       "      <td>0.662582</td>\n",
       "      <td>0.675868</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.881535</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>0.309699</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.675654</td>\n",
       "      <td>0.662582</td>\n",
       "      <td>0.675214</td>\n",
       "      <td>0.009694</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.203749</td>\n",
       "      <td>0.024041</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.706699</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.701520</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.346109</td>\n",
       "      <td>0.076506</td>\n",
       "      <td>0.324994</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.701797</td>\n",
       "      <td>0.700980</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.701797</td>\n",
       "      <td>0.701683</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18.480057</td>\n",
       "      <td>0.111807</td>\n",
       "      <td>0.483685</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.698776</td>\n",
       "      <td>0.702614</td>\n",
       "      <td>0.697712</td>\n",
       "      <td>0.706699</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.701847</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.815874</td>\n",
       "      <td>0.033027</td>\n",
       "      <td>0.132577</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.688980</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.677288</td>\n",
       "      <td>0.686162</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.583226</td>\n",
       "      <td>0.061434</td>\n",
       "      <td>0.255994</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.688980</td>\n",
       "      <td>0.682190</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.678922</td>\n",
       "      <td>0.685672</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.360275</td>\n",
       "      <td>0.109339</td>\n",
       "      <td>0.379568</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.688725</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.686325</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.271639</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.688163</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>0.674020</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.673254</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.529314</td>\n",
       "      <td>0.076020</td>\n",
       "      <td>0.231062</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.672386</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.676520</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.768269</td>\n",
       "      <td>0.110884</td>\n",
       "      <td>0.346861</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1500</td>\n",
       "      <td>42</td>\n",
       "      <td>{'rfc__class_weight': 'balanced', 'rfc__max_de...</td>\n",
       "      <td>0.694694</td>\n",
       "      <td>0.669118</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.676357</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.318658      0.058411         0.104045        0.008570   \n",
       "1        4.573491      0.096270         0.190555        0.002927   \n",
       "2        6.840107      0.197343         0.282089        0.002942   \n",
       "3        1.624615      0.020397         0.093181        0.001943   \n",
       "4        3.238793      0.054916         0.177897        0.002050   \n",
       "5        4.739683      0.064339         0.270101        0.023248   \n",
       "6        1.456939      0.015529         0.089320        0.000478   \n",
       "7        2.861272      0.034160         0.169892        0.002214   \n",
       "8        4.256708      0.030177         0.247809        0.001791   \n",
       "9        4.277533      0.067883         0.135058        0.000474   \n",
       "10       8.576495      0.056847         0.261771        0.001782   \n",
       "11      12.737133      0.172062         0.389302        0.001426   \n",
       "12       2.290345      0.013868         0.115204        0.000478   \n",
       "13       4.540483      0.033923         0.221917        0.001201   \n",
       "14       6.789670      0.057322         0.340070        0.021676   \n",
       "15       1.989135      0.011709         0.109460        0.001683   \n",
       "16       3.948893      0.032455         0.209460        0.001994   \n",
       "17       5.881535      0.042614         0.309699        0.002136   \n",
       "18       6.203749      0.024041         0.166000        0.001573   \n",
       "19      12.346109      0.076506         0.324994        0.002842   \n",
       "20      18.480057      0.111807         0.483685        0.005899   \n",
       "21       2.815874      0.033027         0.132577        0.001857   \n",
       "22       5.583226      0.061434         0.255994        0.003229   \n",
       "23       8.360275      0.109339         0.379568        0.005834   \n",
       "24       2.271639      0.031224         0.119724        0.001922   \n",
       "25       4.529314      0.076020         0.231062        0.003380   \n",
       "26       6.768269      0.110884         0.346861        0.008413   \n",
       "\n",
       "   param_rfc__class_weight param_rfc__max_depth param_rfc__min_samples_leaf  \\\n",
       "0                 balanced                   25                           1   \n",
       "1                 balanced                   25                           1   \n",
       "2                 balanced                   25                           1   \n",
       "3                 balanced                   25                           3   \n",
       "4                 balanced                   25                           3   \n",
       "5                 balanced                   25                           3   \n",
       "6                 balanced                   25                           5   \n",
       "7                 balanced                   25                           5   \n",
       "8                 balanced                   25                           5   \n",
       "9                 balanced                   50                           1   \n",
       "10                balanced                   50                           1   \n",
       "11                balanced                   50                           1   \n",
       "12                balanced                   50                           3   \n",
       "13                balanced                   50                           3   \n",
       "14                balanced                   50                           3   \n",
       "15                balanced                   50                           5   \n",
       "16                balanced                   50                           5   \n",
       "17                balanced                   50                           5   \n",
       "18                balanced                  100                           1   \n",
       "19                balanced                  100                           1   \n",
       "20                balanced                  100                           1   \n",
       "21                balanced                  100                           3   \n",
       "22                balanced                  100                           3   \n",
       "23                balanced                  100                           3   \n",
       "24                balanced                  100                           5   \n",
       "25                balanced                  100                           5   \n",
       "26                balanced                  100                           5   \n",
       "\n",
       "   param_rfc__n_estimators param_rfc__random_state  \\\n",
       "0                      500                      42   \n",
       "1                     1000                      42   \n",
       "2                     1500                      42   \n",
       "3                      500                      42   \n",
       "4                     1000                      42   \n",
       "5                     1500                      42   \n",
       "6                      500                      42   \n",
       "7                     1000                      42   \n",
       "8                     1500                      42   \n",
       "9                      500                      42   \n",
       "10                    1000                      42   \n",
       "11                    1500                      42   \n",
       "12                     500                      42   \n",
       "13                    1000                      42   \n",
       "14                    1500                      42   \n",
       "15                     500                      42   \n",
       "16                    1000                      42   \n",
       "17                    1500                      42   \n",
       "18                     500                      42   \n",
       "19                    1000                      42   \n",
       "20                    1500                      42   \n",
       "21                     500                      42   \n",
       "22                    1000                      42   \n",
       "23                    1500                      42   \n",
       "24                     500                      42   \n",
       "25                    1000                      42   \n",
       "26                    1500                      42   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.703673   \n",
       "1   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.702041   \n",
       "2   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.701224   \n",
       "3   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.686531   \n",
       "4   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.692245   \n",
       "5   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.693061   \n",
       "6   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.679184   \n",
       "7   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.683265   \n",
       "8   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.684898   \n",
       "9   {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.706939   \n",
       "10  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.708571   \n",
       "11  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.706939   \n",
       "12  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.695510   \n",
       "13  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.694694   \n",
       "14  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.693878   \n",
       "15  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.689796   \n",
       "16  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.689796   \n",
       "17  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.692245   \n",
       "18  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.697959   \n",
       "19  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.697959   \n",
       "20  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.698776   \n",
       "21  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.688980   \n",
       "22  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.688980   \n",
       "23  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.692245   \n",
       "24  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.688163   \n",
       "25  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.697143   \n",
       "26  {'rfc__class_weight': 'balanced', 'rfc__max_de...           0.694694   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.692810           0.695261           0.693627   \n",
       "1            0.691176           0.698529           0.695261   \n",
       "2            0.687092           0.702614           0.695261   \n",
       "3            0.678105           0.681373           0.682190   \n",
       "4            0.673203           0.687092           0.683824   \n",
       "5            0.670752           0.687092           0.686275   \n",
       "6            0.667484           0.678105           0.678105   \n",
       "7            0.665033           0.687092           0.673203   \n",
       "8            0.660948           0.688725           0.674837   \n",
       "9            0.705065           0.710784           0.709967   \n",
       "10           0.704248           0.711601           0.709967   \n",
       "11           0.698529           0.707516           0.706699   \n",
       "12           0.690359           0.685458           0.686275   \n",
       "13           0.688725           0.687908           0.687908   \n",
       "14           0.688725           0.684641           0.688725   \n",
       "15           0.674020           0.675654           0.674837   \n",
       "16           0.671569           0.678105           0.677288   \n",
       "17           0.670752           0.674837           0.675654   \n",
       "18           0.696078           0.703431           0.706699   \n",
       "19           0.701797           0.700980           0.705882   \n",
       "20           0.702614           0.697712           0.706699   \n",
       "21           0.687908           0.690359           0.686275   \n",
       "22           0.682190           0.690359           0.687908   \n",
       "23           0.683824           0.688725           0.690359   \n",
       "24           0.660131           0.674020           0.676471   \n",
       "25           0.670752           0.674837           0.672386   \n",
       "26           0.669118           0.674837           0.676471   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.676471         0.692369        0.008840                9  \n",
       "1            0.680556         0.693513        0.007407                8  \n",
       "2            0.681373         0.693513        0.008173                7  \n",
       "3            0.658497         0.677339        0.009797               18  \n",
       "4            0.662582         0.679789        0.010623               16  \n",
       "5            0.661765         0.679789        0.011646               17  \n",
       "6            0.661765         0.672928        0.007028               27  \n",
       "7            0.660131         0.673745        0.010299               24  \n",
       "8            0.659314         0.673744        0.012017               25  \n",
       "9            0.698529         0.706257        0.004379                2  \n",
       "10           0.702614         0.707401        0.003419                1  \n",
       "11           0.698529         0.703643        0.004183                3  \n",
       "12           0.674837         0.686488        0.006830               10  \n",
       "13           0.669935         0.685834        0.008346               13  \n",
       "14           0.670752         0.685344        0.007863               15  \n",
       "15           0.657680         0.674397        0.010183               23  \n",
       "16           0.662582         0.675868        0.008900               21  \n",
       "17           0.662582         0.675214        0.009694               22  \n",
       "18           0.703431         0.701520        0.003910                6  \n",
       "19           0.701797         0.701683        0.002531                5  \n",
       "20           0.703431         0.701847        0.003261                4  \n",
       "21           0.677288         0.686162        0.004634               12  \n",
       "22           0.678922         0.685672        0.004373               14  \n",
       "23           0.676471         0.686325        0.005665               11  \n",
       "24           0.667484         0.673254        0.009367               26  \n",
       "25           0.667484         0.676520        0.010585               19  \n",
       "26           0.666667         0.676357        0.009848               20  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_rfc.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__class_weight': 'balanced',\n",
       " 'rfc__max_depth': 50,\n",
       " 'rfc__min_samples_leaf': 1,\n",
       " 'rfc__n_estimators': 1000,\n",
       " 'rfc__random_state': 42}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
